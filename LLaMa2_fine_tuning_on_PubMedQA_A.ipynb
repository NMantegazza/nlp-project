{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwaHNcfPBFij"
      },
      "source": [
        "# Fine-tuning a pre-trained LLM\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1CQcMCdr_vC"
      },
      "source": [
        "In this notebook, we will fine-tune the base [LLaMA2-7B](https://huggingface.co/meta-llama/Llama-2-7b-hf) model from Hugging Face on the PubMedQA dataset. The goal is to train the model to generate both a final decision (“yes” or “no”) and a long-form explanation for each medical question, improving its ability to provide accurate and well-structured answers to medical questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mFi09MR37kO"
      },
      "source": [
        "##Installations and imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwhWRlZgDcUO"
      },
      "source": [
        "Imports:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TG1SlrUDb_m",
        "outputId": "4e22e9c6-f322-4761-bad5-61b396e6ff74"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y transformers accelerate trl peft bitsandbytes\n",
        "!pip install -U \\\n",
        "  transformers \\\n",
        "  accelerate \\\n",
        "  trl \\\n",
        "  peft \\\n",
        "  bitsandbytes \\\n",
        "  evaluate \\\n",
        "  rouge_score \\\n",
        "  bert_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkJEq5CODhdq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import evaluate\n",
        "from transformers import  AutoModelForCausalLM, AutoTokenizer, pipeline, BitsAndBytesConfig, TrainingArguments, EarlyStoppingCallback\n",
        "from peft import LoraConfig, PeftModel\n",
        "from peft import prepare_model_for_kbit_training, get_peft_model\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from accelerate import Accelerator\n",
        "from google.colab import drive\n",
        "from sklearn.metrics import classification_report\n",
        "from huggingface_hub import login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUIiIIDuBNxg"
      },
      "source": [
        "We will use Llama-2-7B from Hugging Face and fine-tune it using our datasets for better performances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu6-pDbwlBzp",
        "outputId": "6875b303-cae3-4f30-f386-7aa226b1d097"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XuC7LKOg0TdR"
      },
      "outputs": [],
      "source": [
        "#some global variable\n",
        "use_context = True\n",
        "dataset_path = \"/content/drive/MyDrive/NLP/Assignment/PQA-A.parquet\"\n",
        "model_name = \"meta-llama/Llama-2-7b-hf\"\n",
        "save_path = \"/content/drive/MyDrive/NLP/Assignment/adapter-weights\"\n",
        "merged_path = \"/content/drive/MyDrive/NLP/Assignment/final-model\"\n",
        "max_new_tokens = max_seq_length = 512"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jXU0CLYN9xs"
      },
      "source": [
        "## Dataset preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8M7h7JTd6uX"
      },
      "source": [
        "We chose to use the `pqa_artificial` dataset because it includes labeled data and contains more than 1,000 samples, which makes it possible to extract a balanced subset of \"yes\" and \"no\" answers for fine-tuning.\n",
        "\n",
        "The preprocessing steps involve:\n",
        "- Removing unnecessary fields\n",
        "- Filtering out uncertain samples (`final_decision` = \"maybe\")\n",
        "- Sampling 1,000 “yes” and 1,000 “no” answers to keep the classes balanced and have enough data without making training take too long.\n",
        "- Flattening the context field for easier input formatting\n",
        "- Combining the final_decision and long_answer into a full answer to better guide the model generated responses.\n",
        "- Formatting each example into an instruction-style prompt\n",
        "\n",
        "The processed data is then split into training and evaluation sets, and converted into Hugging Face `Dataset` objects for model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "pv0UyaYUECyE",
        "outputId": "26f92b1e-54fd-4784-e4c6-4e3d94fcf1a3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-39c91e66-e529-48bc-b348-a4f0b0827241\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pubid</th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "      <th>long_answer</th>\n",
              "      <th>final_decision</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25429730</td>\n",
              "      <td>Are group 2 innate lymphoid cells ( ILC2s ) in...</td>\n",
              "      <td>{'contexts': ['Chronic rhinosinusitis (CRS) is...</td>\n",
              "      <td>As ILC2s are elevated in patients with CRSwNP,...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25433161</td>\n",
              "      <td>Does vagus nerve contribute to the development...</td>\n",
              "      <td>{'contexts': ['Phosphatidylethanolamine N-meth...</td>\n",
              "      <td>Neuronal signals via the hepatic vagus nerve c...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>25445714</td>\n",
              "      <td>Does psammaplin A induce Sirtuin 1-dependent a...</td>\n",
              "      <td>{'contexts': ['Psammaplin A (PsA) is a natural...</td>\n",
              "      <td>PsA significantly inhibited MCF-7/adr cells pr...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25431941</td>\n",
              "      <td>Is methylation of the FGFR2 gene associated wi...</td>\n",
              "      <td>{'contexts': ['This study examined links betwe...</td>\n",
              "      <td>We identified a novel biologically plausible c...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25432519</td>\n",
              "      <td>Do tumor-infiltrating immune cell profiles and...</td>\n",
              "      <td>{'contexts': ['Tumor microenvironment immunity...</td>\n",
              "      <td>Breast cancer immune cell subpopulation profil...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39c91e66-e529-48bc-b348-a4f0b0827241')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-39c91e66-e529-48bc-b348-a4f0b0827241 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-39c91e66-e529-48bc-b348-a4f0b0827241');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1bb26eed-3cce-4508-ade7-a2303cacc6ae\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1bb26eed-3cce-4508-ade7-a2303cacc6ae')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1bb26eed-3cce-4508-ade7-a2303cacc6ae button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      pubid                                           question  \\\n",
              "0  25429730  Are group 2 innate lymphoid cells ( ILC2s ) in...   \n",
              "1  25433161  Does vagus nerve contribute to the development...   \n",
              "2  25445714  Does psammaplin A induce Sirtuin 1-dependent a...   \n",
              "3  25431941  Is methylation of the FGFR2 gene associated wi...   \n",
              "4  25432519  Do tumor-infiltrating immune cell profiles and...   \n",
              "\n",
              "                                             context  \\\n",
              "0  {'contexts': ['Chronic rhinosinusitis (CRS) is...   \n",
              "1  {'contexts': ['Phosphatidylethanolamine N-meth...   \n",
              "2  {'contexts': ['Psammaplin A (PsA) is a natural...   \n",
              "3  {'contexts': ['This study examined links betwe...   \n",
              "4  {'contexts': ['Tumor microenvironment immunity...   \n",
              "\n",
              "                                         long_answer final_decision  \n",
              "0  As ILC2s are elevated in patients with CRSwNP,...            yes  \n",
              "1  Neuronal signals via the hepatic vagus nerve c...            yes  \n",
              "2  PsA significantly inhibited MCF-7/adr cells pr...            yes  \n",
              "3  We identified a novel biologically plausible c...            yes  \n",
              "4  Breast cancer immune cell subpopulation profil...            yes  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#load dataset\n",
        "dataset = pd.read_parquet(dataset_path)\n",
        "dataset.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frycH5EarkIQ"
      },
      "outputs": [],
      "source": [
        "def preprocess_df(df):\n",
        "    #drop pubid\n",
        "    df = df.drop(columns=['pubid'])\n",
        "\n",
        "    #Keep only relevant field in the 'context' dict (and string)\n",
        "    df['context'] = df['context'].apply(\n",
        "        lambda x: ' '.join(x['contexts']) if isinstance(x, dict) and 'contexts' in x else str(x)\n",
        "    )\n",
        "    #Extract 1k rows with 'final_answer' 'yes' and 1k rows 'no and concatenate it\n",
        "    df_yes = df[df['final_decision'] == 'yes'].sample(n=1000, random_state=42)\n",
        "    df_no = df[df['final_decision'] == 'no'].sample(n=1000, random_state=42)\n",
        "    df = pd.concat([df_yes, df_no])\n",
        "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    df['question'] = df['question'].apply(lambda x: str(x))\n",
        "    #Combine 'final_answer' and 'long_answer' as 'answer'\n",
        "    df['answer'] = df['final_decision'] + ', ' + df['long_answer']\n",
        "    df['answer'] = df['answer'].apply(lambda x: str(x))\n",
        "    #Drop long_answer and final_decision\n",
        "    df = df.drop(columns=['long_answer'])\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KldJjBTH4RsX",
        "outputId": "3cc29471-039f-4dfb-ee41-04171191dfb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2000 entries, 0 to 1999\n",
            "Data columns (total 4 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   question        2000 non-null   object\n",
            " 1   context         2000 non-null   object\n",
            " 2   final_decision  2000 non-null   object\n",
            " 3   answer          2000 non-null   object\n",
            "dtypes: object(4)\n",
            "memory usage: 62.6+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "dataset = preprocess_df(dataset)\n",
        "print(dataset.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8CYtzN9KfLq"
      },
      "outputs": [],
      "source": [
        "def formatting_prompts_func(row):\n",
        "    return (\n",
        "        f\"### Instruction:\\n\"\n",
        "        f\"You are a medical expert. Based on the following context, answer the question with 'Yes' or 'No', followed by a clear and accurate explanation.\\n\"\n",
        "        f\"### Context:\\n{row['context']}\\n\"\n",
        "        f\"### Question:\\n{row['question']}\\n\"\n",
        "        f\"### Answer:\\n{row['answer']}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1h-4VlH-pQvL"
      },
      "source": [
        "We chose this specific prompt format—based on the [Stanford Alpaca](https://github.com/tatsu-lab/stanford_alpaca?tab=readme-ov-file#data-release) style—because it aligns well with how LLaMA2 models are typically fine-tuned. The structured ### Instruction, ### Context, ### Question, and ### Answer format provides clear task framing, which should help the model better understand its role and expected output.<br>\n",
        "As we can see from the prompt, we chose to have the model give both the `final answer` (“yes” or “no”) and an explanation (`long_answer`). That's because, when we only asked for an explanation, the model often gave vague or general responses and didn't clearly answer the question. By asking for a direct “yes” or “no” first, we made sure the model stayed focused and gave clearer, more useful answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "n_iOKKr_lKev",
        "outputId": "e1f2603d-042d-4987-a13e-94e60c5beb05"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 2000,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2000,\n        \"samples\": [\n          \"Do norgestimate and medroxyprogesterone acetate attenuate the atheroprotective effects of 17beta-estradiol in ovariectomized , apolipoprotein E-deficient mice?\",\n          \"Is platelet 5-HT2A-receptor-mediated induction of aggregation altered in major depression?\",\n          \"Does iron inhibit replication of infectious hepatitis C virus in permissive Huh7.5.1 cells?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2000,\n        \"samples\": [\n          \"To determine whether progestins counteract the cardioprotective effects of estrogen. Controlled animal study. Academic laboratory environment. Female apolipoprotein E-deficient mice. Mice were randomly assigned to groups receiving a sham operation plus placebo pellet, bilateral gonadectomy plus placebo pellet, or gonadectomy plus one of nine combinations of estrogen/progestin SC pellets. Total plasma cholesterol, body weight, fat depot weight, uterine weight and size, and the cross-sectional area of fatty streaks in the aortic sinus were measured in each animal. After 8 weeks of treatment, plasma cholesterol levels were significantly higher only in the ovariectomized and sham-operated animals that received placebo pellets. No differences in plasma cholesterol were observed relative to the type or amount of progestin administered. There was a reduction in fatty streaks in all of the hormone treatment groups as compared with both the ovariectomized and sham-operated animals that received placebo pellets.\",\n          \"Studies of the 5-HT(2A) receptor subtype in major depression have focused on the density of these receptors in neuronal cells and platelets, showing an up-regulation secondary to a deficit in serotonergic activity in major depression. However, their functional state has often been disregarded. The aim of the study was to investigate whether depressed patients show abnormalities in the function of the 5-HT(2A) receptor pathway in platelets. The percentage of serotonin-amplified platelet aggregation to adenosine diphosphate (ADP) was assessed in 30 untreated patients with major depressive disorder and in 15 controls. Since 5-HT(2A) platelet receptors mediate the serotonin-induced platelet aggregation response, this index was used as a measure of the functional status of the platelet 5-HT(2A) receptor pathway. There was no significant difference in the percentage of serotonin-amplified platelet aggregation to ADP between depressed patients and controls. No correlation with the severity of depression, as assessed by the Hamilton scale, was found.\",\n          \"Chronic infection with hepatitis C virus (HCV) is often associated with elevated hepatic iron levels. Excess iron is known to promote oxidative stress and exacerbate liver disease. Nevertheless, biochemical studies in subgenomic HCV replicon systems showed that iron can also suppress the expression of viral RNA and proteins by inhibiting the enzymatic activity of the RNA polymerase NS5B. To explore the physiological relevance of this response, we evaluated the effects of iron during infection of permissive Huh7.5.1 hepatoma cells with HCV. We utilized Fe-SIH (iron complexed with salicylaldehyde isonicotinoyl hydrazone), a cell permeable and highly efficient iron donor. Treatments of infected cells with Fe-SIH drastically reduced the expression of viral proteins (core and NS3) and RNA, in a dose-dependent manner. The inhibition was dramatic when Fe-SIH was administered simultaneously with the HCV inoculum or early afterwards, while pre-treatment of cells with Fe-SIH before infection failed to elicit antiviral responses. Iron chelation with SIH did not significantly alter the expression of viral proteins.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"final_decision\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2000,\n        \"samples\": [\n          \"no, There were no significant differences in lesion area in response to estrogen alone or to estrogen plus the different types and doses of progestins.\",\n          \"no, The results showed no consistent changes in the platelet aggregating responses to serotonin in the depressed patients. Therefore this study does not support the hypothesis of an alteration of the functional status of platelet 5-HT(2A) receptors in major depression.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2000,\n        \"samples\": [\n          \"### Instruction:\\nYou are a medical expert. Based on the following context, answer the question with 'Yes' or 'No', followed by a clear and accurate explanation.\\n### Context:\\nTo determine whether progestins counteract the cardioprotective effects of estrogen. Controlled animal study. Academic laboratory environment. Female apolipoprotein E-deficient mice. Mice were randomly assigned to groups receiving a sham operation plus placebo pellet, bilateral gonadectomy plus placebo pellet, or gonadectomy plus one of nine combinations of estrogen/progestin SC pellets. Total plasma cholesterol, body weight, fat depot weight, uterine weight and size, and the cross-sectional area of fatty streaks in the aortic sinus were measured in each animal. After 8 weeks of treatment, plasma cholesterol levels were significantly higher only in the ovariectomized and sham-operated animals that received placebo pellets. No differences in plasma cholesterol were observed relative to the type or amount of progestin administered. There was a reduction in fatty streaks in all of the hormone treatment groups as compared with both the ovariectomized and sham-operated animals that received placebo pellets.\\n### Question:\\nDo norgestimate and medroxyprogesterone acetate attenuate the atheroprotective effects of 17beta-estradiol in ovariectomized , apolipoprotein E-deficient mice?\\n### Answer:\\nno, There were no significant differences in lesion area in response to estrogen alone or to estrogen plus the different types and doses of progestins.\",\n          \"### Instruction:\\nYou are a medical expert. Based on the following context, answer the question with 'Yes' or 'No', followed by a clear and accurate explanation.\\n### Context:\\nStudies of the 5-HT(2A) receptor subtype in major depression have focused on the density of these receptors in neuronal cells and platelets, showing an up-regulation secondary to a deficit in serotonergic activity in major depression. However, their functional state has often been disregarded. The aim of the study was to investigate whether depressed patients show abnormalities in the function of the 5-HT(2A) receptor pathway in platelets. The percentage of serotonin-amplified platelet aggregation to adenosine diphosphate (ADP) was assessed in 30 untreated patients with major depressive disorder and in 15 controls. Since 5-HT(2A) platelet receptors mediate the serotonin-induced platelet aggregation response, this index was used as a measure of the functional status of the platelet 5-HT(2A) receptor pathway. There was no significant difference in the percentage of serotonin-amplified platelet aggregation to ADP between depressed patients and controls. No correlation with the severity of depression, as assessed by the Hamilton scale, was found.\\n### Question:\\nIs platelet 5-HT2A-receptor-mediated induction of aggregation altered in major depression?\\n### Answer:\\nno, The results showed no consistent changes in the platelet aggregating responses to serotonin in the depressed patients. Therefore this study does not support the hypothesis of an alteration of the functional status of platelet 5-HT(2A) receptors in major depression.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "dataset"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-9b70e22d-1e4e-4a7b-a9ca-9512585f99eb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "      <th>final_decision</th>\n",
              "      <th>answer</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Does tyrosinemia I , a model for human disease...</td>\n",
              "      <td>Medical treatment of tyrosinemia I relies on t...</td>\n",
              "      <td>no</td>\n",
              "      <td>no, Normalization of hepatic collagen formatio...</td>\n",
              "      <td>### Instruction:\\nYou are a medical expert. Ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Is primary sclerosing cholangitis associated w...</td>\n",
              "      <td>Cigarette smoking is thought to protect agains...</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes, The odds of having primary sclerosing cho...</td>\n",
              "      <td>### Instruction:\\nYou are a medical expert. Ba...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b70e22d-1e4e-4a7b-a9ca-9512585f99eb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9b70e22d-1e4e-4a7b-a9ca-9512585f99eb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9b70e22d-1e4e-4a7b-a9ca-9512585f99eb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-552e92cb-feda-490e-bb07-644693f7f254\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-552e92cb-feda-490e-bb07-644693f7f254')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-552e92cb-feda-490e-bb07-644693f7f254 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  Does tyrosinemia I , a model for human disease...   \n",
              "1  Is primary sclerosing cholangitis associated w...   \n",
              "\n",
              "                                             context final_decision  \\\n",
              "0  Medical treatment of tyrosinemia I relies on t...             no   \n",
              "1  Cigarette smoking is thought to protect agains...            yes   \n",
              "\n",
              "                                              answer  \\\n",
              "0  no, Normalization of hepatic collagen formatio...   \n",
              "1  yes, The odds of having primary sclerosing cho...   \n",
              "\n",
              "                                                text  \n",
              "0  ### Instruction:\\nYou are a medical expert. Ba...  \n",
              "1  ### Instruction:\\nYou are a medical expert. Ba...  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['text'] = dataset.apply(formatting_prompts_func, axis=1)\n",
        "dataset.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxFYs_SUmlQ-"
      },
      "source": [
        "Now in the 'text' column we have the training prompt for fine tuning the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_75w5U73k8Gs",
        "outputId": "f157a9b0-9330-4ff6-d07d-2a2f93713b1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1600, 400)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset, eval_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "len(train_dataset), len(eval_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OCCIR2Nm3l7",
        "outputId": "24846c0f-56e4-480e-d75a-fc8430e74738"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['question', 'context', 'final_decision', 'answer', 'text', '__index_level_0__'],\n",
            "    num_rows: 1600\n",
            "})\n",
            "Dataset({\n",
            "    features: ['question', 'context', 'final_decision', 'answer', 'text', '__index_level_0__'],\n",
            "    num_rows: 400\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# Convert pandas Series to Hugging Face Dataset objects\n",
        "train_dataset_hf = Dataset.from_pandas(train_dataset)\n",
        "eval_dataset_hf = Dataset.from_pandas(eval_dataset)\n",
        "\n",
        "print(train_dataset_hf)\n",
        "print(eval_dataset_hf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IriKU-odPvtm"
      },
      "source": [
        "All processing steps are done, we can continue."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa9okNi1P1p0"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU4-GOxqP7TT"
      },
      "source": [
        "## Load the base model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAaBHxh0CyfG"
      },
      "source": [
        "To access the official LLaMA models from Meta, you need a personal access token, which can be generated at:<br>\n",
        "https://huggingface.co/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6O8lfBNGtrq"
      },
      "outputs": [],
      "source": [
        "#A personal token is needed to access the model\n",
        "my_token = \"...\"\n",
        "login(token=my_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvFyJgMzLHk4"
      },
      "source": [
        "We load the model from Hugging Face with weight quantization to reduce GPU usage. In simple terms, quantization means converting the model's 32-bit weights into smaller 4-bit numbers, which makes the model use less memory and run more efficiently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTzt6SWGAkEv"
      },
      "outputs": [],
      "source": [
        "def load_model_and_tokenizer(model_name):\n",
        "\n",
        "  quantization_config = BitsAndBytesConfig(\n",
        "      load_in_4bit=True,\n",
        "      bnb_4bit_compute_dtype=torch.float16,\n",
        "      bnb_4bit_quant_type=\"nf4\",\n",
        "      bnb_4bit_use_double_quant=False,\n",
        "  )\n",
        "\n",
        "  device_index = Accelerator().process_index\n",
        "  device_map = {\"\": device_index}\n",
        "\n",
        "  #Import the model from hf with quantization config\n",
        "  model = AutoModelForCausalLM.from_pretrained(\n",
        "      model_name,\n",
        "      torch_dtype=torch.float16,\n",
        "      device_map=device_map,\n",
        "      quantization_config=quantization_config\n",
        "  )\n",
        "\n",
        "  #Import also LLaMa tokenizer\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
        "  tokenizer.pad_token = tokenizer.eos_token\n",
        "  tokenizer.padding_side = \"right\"\n",
        "  return model, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917,
          "referenced_widgets": [
            "811a49ab12c84add92ecea028be24481",
            "2e2ae1f0ef524f44bbf7f3ebe4740bdc",
            "241e74e641374985a800c1e0ac0cd7bb",
            "a055ecb21f634a43950985febe30e73b",
            "063d991d23e144ecb175434f627719c3",
            "3132ea186dd74d98a88f9c3aca2be584",
            "c2523813c8f046719e7150f9756bab13",
            "b2b38094eda041b0b5c7e5e76da38e2a",
            "f45323f9224147b599249470d983c00c",
            "8a3c6e1fb8e54c47a511f77d9bf11e30",
            "2d1f443385b74f1e840de58482985c69",
            "9108d16f954944f9a8cdd47f3860c3ea",
            "40fe0dbea29b48aba4e1527f87f8e58a",
            "0a71a3dd20e948a3b5d2ed85880498fb",
            "0d9290bf94d1450db62126ced56db795",
            "693acdbb23de4822a1f4be48e7d5ea29",
            "337240e0deb74eb6909aab9b2af974a1",
            "913e27194ca548fdbdcc4a2e002832ee",
            "7d8c9381326a4a078a9716f685eb51ff",
            "4574472b1a1c4803b2817a289c6b9ae2",
            "35e57b45220e462d88cf2821b1f7a6ce",
            "5ad6ab9d2691448cb9ed0c677f64626c",
            "a3c0a58383704e8ba66fe04d6bb320d5",
            "ab96290d044341c983f4520fb1f2d6dc",
            "5925346f2d7c4238a2b71c11af90081d",
            "e25c691c87424c1ebdc3205662625e10",
            "036e8d62610446cb990437b8ebb758ae",
            "a6f7dd5bc21d4a2f9235fee68bab7aa2",
            "d760129be120406c94d440384592c657",
            "7a66a1e67e6547fdb72615a369d4d64d",
            "587f992071f44306ac9778539c3e46c9",
            "e8a91262e5104335ad17c9caef53eba6",
            "bb25717b07bb4f2e8881c1a6cf3cd573",
            "52f2b04ba2e04bb19f654e6f967299d7",
            "b8ebce38c8054a89b9c7d6a226afeb78",
            "b21557f4fede4b499c70a2e9732bfb75",
            "c1e57d0c93ec4fa9904547c56d44fd2d",
            "c47f8f5cdf894d438740e17d1fe5f384",
            "d21a6ad330774f7382e73bcc663ce950",
            "bb703eb4e11a4e4b9237dc8aa7490785",
            "ec43d817b7c34bd09958ba5be7cb5d84",
            "d6a1f37dbbf744d6b9d679a9851a59de",
            "d7f5a902004f4f07bdf23d1d1b3fe1ee",
            "b7039f5b1ff94757899e679b8d33b228",
            "63e451818a454240982dc928c32e19f0",
            "50e909107da74665ba91beb30b23c600",
            "c02f2528dc4f450680931f09781c2da6",
            "8d4f9d48b2c44fc4986e89f0fb0a1349",
            "1b65211f47bb4f42b965af2e14e81fde",
            "ef26584c062c4b2eb24ed0c409c4885e",
            "09500192fc3048428b28e533ac7cb805",
            "80a1650a7ba04bb1acaaf0d33e1019ea",
            "554331c2e5974bfa9b7cecf30b50eb2b",
            "8973a0a87c86493bbb32eec8822c2280",
            "ca1174f160d6416488472ebcde22c857",
            "927034e629614966b59585549671254d",
            "dd50d09af7af43818a01548ac47f1c2c",
            "f042107bf72e4e7082dbcf76611495e8",
            "22c8da70ec4344d89085816f7f00378a",
            "51b8b176011c4f42992b535f5a1473c0",
            "ef6a2e9cf41c4e0887fef0fc6e9a0613",
            "c54a83a24a934b0cb8284808e9d12669",
            "27f742e86db84e9d906d05de9619c0ea",
            "2df1d604fc3742d6a498edf4fafc2473",
            "2cd5fc0a1ca34a9a9a6e5d8c4d01fe12",
            "fce9a48c8d094d598674f911ffbbf571",
            "c4ce93c60f15450482386e3d48217697",
            "94af35035a964ab49655269651e50bc3",
            "7b4ce504647d4530b6d99c83e2f396ac",
            "82daf936d2214ef8905adb75292f39e6",
            "528cd6dbd18e4dc783e1538451d3aa32",
            "e2e7f2b4864f48828619370e2eed7bf5",
            "c452beb577f244e9a0f483ac2fbddf3c",
            "d9d6387af7c2459bafc5ff9b2e9be04e",
            "079b36a65ed3486eb69df2c8d713b4af",
            "708601e3bf924be4ba3b6e01d4fd497f",
            "78519d12329b497aa584dca08e1cc963",
            "5347bdfce94b4f50b9f26921ce2456a7",
            "e05a150b0e554bbebc4dc908002f4f40",
            "6ae04f79a1084a2dae4e399a9cefd3d9",
            "ee987257d8cb43b490a45f3dcd45e761",
            "9a5cbd6824d04f97b7229a8fbda1275f",
            "b5fc7940bad64527baed72a04c3a4f56",
            "75f10f253ed54449abf538521478dea7",
            "069f21ecc1cd4b5e9f2129647c2b6dfb",
            "2016b6cb4bb74844a09dd886f610cac7",
            "4eb2d286483a471da04c72b2bf73418b",
            "ab466b0996034f978429f161d48601a8",
            "6805c614e5a24eaa9681aa4ef876b92f",
            "e06a4aa154db4c11be96c71a57a644ca",
            "dee2f66a300e4639966af43712340ded",
            "e22139665dbe49279aefb5853bd79b56",
            "29df103aaff8411397962ba9a3226350",
            "b4e24545b9614554a43e4745ca57e85c",
            "de22b5062c1d4ca08d53f7de4b889099",
            "7ac9af8c3d70446b8550611a638d4b56",
            "194b011c65504c0e8b17137d83f38586",
            "58876882ec5949d897341059ea6e5e45",
            "56435787043b498d978214c563736847",
            "738749c88ef645349c404d633585726d",
            "3a59980820aa44288b5507815f12d74c",
            "47c652856e85428c9135a8319271f2cf",
            "629255225c0b47759832827df903c90e",
            "e3d8134bfcb84b228a98e32808668212",
            "1fa1dc071d154d10bf4f25fc19ca58b9",
            "5dc2573175fa48d3b35da83a4e2c4a63",
            "07129cf7b8a94753b9aabab79cedc307",
            "2d81a362a10d4f87af05c1df2ac503c8",
            "4bfc8bef494a4f7bababa872313db740",
            "8bbf681a96b1422db21152aae3b063fd",
            "621da94881db41379733d626c2469ebf",
            "88001dacd5ed401e8c02e4042a91fe4d",
            "85d05ec591c3472ca9eb6ae0c7b0915c",
            "4de7097c462a446f819dd22bb28026f4",
            "c98d7598e661449897377b73b7ae625e",
            "c8ee8685283f443b989fab7332148264",
            "c7e810e2d1e740d2a77c0a46ea3dd89e",
            "7fc2527313414814ab1f823c19ba94e2",
            "2f9db467e431400ea61643d75e987176",
            "2b4b0fd7be4f4003bdfe9fc620855bca",
            "dd52cf3b377a41a1bb7a7310f3c197b5"
          ]
        },
        "id": "eq-YdkVGeU0M",
        "outputId": "4a1d9762-7d5a-4bb8-f30d-8fa16b61343d"
      },
      "outputs": [],
      "source": [
        "base_model, base_tokenizer = load_model_and_tokenizer(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYZbY67lQnSI"
      },
      "source": [
        "## Fine-tuning the base model on PubMedQA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAjkE23ZQpEd"
      },
      "source": [
        "To better manage GPU usage, we use `LoRA` (Low-Rank Adaptation).\n",
        "LoRA is a parameter-efficient fine-tuning (`PEFT`) technique that “freezes” most of the original model's weights, allowing only a small portion to be updated during fine-tuning. This greatly reduces the computational and memory requirements.<br>\n",
        "Here's the LoRA configuration:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooJgisHOQmCJ"
      },
      "outputs": [],
      "source": [
        "lora_configs = LoraConfig(\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    r=16,\n",
        "    bias='none',\n",
        "    task_type='CAUSAL_LM',\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndIPZgCZWa2E"
      },
      "source": [
        "Now the model is ready, we still need to define the trainer\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5owZRS9YClY"
      },
      "source": [
        "Now that the model is ready, we still need to define the trainer.<br>\n",
        "We'll use `SFTTrainer` from the `trl` library, as it provides good integration with LoRA technique."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQ2_hw_OXc3g"
      },
      "outputs": [],
      "source": [
        "#Trainer configuration\n",
        "training_args = SFTConfig(\n",
        "    output_dir=\"/content/drive/MyDrive/NLP/Assignment/llama2-pubmedqa-a\",\n",
        "    logging_steps=50,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=50,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=100,\n",
        "    load_best_model_at_end=True,\n",
        "    run_name=\"llama2-big-run\",\n",
        "    max_seq_length=512,\n",
        "    report_to=[],\n",
        "    gradient_accumulation_steps=4,\n",
        "    gradient_checkpointing=True,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    learning_rate=5e-5,\n",
        "    num_train_epochs=3,\n",
        "    bf16=True,\n",
        "    packing=False,\n",
        "    save_total_limit=2,\n",
        "    dataset_text_field='text',\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=base_model,\n",
        "    train_dataset=train_dataset_hf,\n",
        "    eval_dataset=eval_dataset_hf,\n",
        "    args=training_args,\n",
        "    peft_config=lora_configs,\n",
        "    formatting_func=None,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aetxk4mFiQel"
      },
      "source": [
        "We can finally start the training phase.<br>\n",
        "The training runs for 3 epochs with a batch size of 4 and a learning rate of 5e-5. The model is evaluated every 50 steps. Early stopping is also enabled to prevent overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "TTWk6TU2rvpI",
        "outputId": "4bb180ba-46a4-46fd-83d6-afa5cdda7935"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 21:35, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.373900</td>\n",
              "      <td>1.250758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.241800</td>\n",
              "      <td>1.222652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.218600</td>\n",
              "      <td>1.219042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.232400</td>\n",
              "      <td>1.217216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.220700</td>\n",
              "      <td>1.216514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.217800</td>\n",
              "      <td>1.216211</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer.train()\n",
        "trainer.save_model(save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc2-gq9etM0X"
      },
      "source": [
        "We can notice the validation loss hitting a plateu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzAeXKPmApuR"
      },
      "source": [
        "##Store the tuned model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swRyn1ebCcSe"
      },
      "source": [
        "Now that we have the fine-tuned model we can store it, then load it and perform inference on it to see if it performs better!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f3a48262585d4d229c61b6e43010df21",
            "1faf6c8be58248b19cf1da9845a1a583",
            "478e6b809d634dcbb25326e108075d09",
            "35798f9558d2496494c9157318f31855",
            "3704bae5a4b24bd1a150e0ebccab57d4",
            "c29ddf724d9c46c989d80e4693a1016a",
            "94a553fcc381462f9f4c8eef44ff99df",
            "a0555ceaae234dbc90bb0f149de3922f",
            "5cb612bc801f425fbef8cd11f08d4d67",
            "8ae0f59e8c9b458a8dcc2a4a4906dcb6",
            "73ca09f67f4645d298760513ced1f537"
          ]
        },
        "id": "4ffvP8i5Adqs",
        "outputId": "0c98557a-de30-4d34-eaf4-e24ce1009393"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3a48262585d4d229c61b6e43010df21",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load base model (not quantized)\n",
        "fresh_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# Load adapter on top of base\n",
        "peft_model = PeftModel.from_pretrained(fresh_model, save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6xmCpoNAre7",
        "outputId": "c5056dce-2651-486f-ac3b-757b7ea8dad4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/NLP/Assignment/final-model/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/NLP/Assignment/final-model/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/NLP/Assignment/final-model/tokenizer.model',\n",
              " '/content/drive/MyDrive/NLP/Assignment/final-model/added_tokens.json')"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Merge the adapter and the original LLaMa model\n",
        "merged_model = peft_model.merge_and_unload()\n",
        "#Save the fine-tuned model (and tokenizer)\n",
        "merged_model.save_pretrained(merged_path)\n",
        "base_tokenizer.save_pretrained(merged_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljkidUEpDpqc"
      },
      "outputs": [],
      "source": [
        "#Delete the fresh base model that was reloaded only to store the tuned version.\n",
        "#The original base model with quantization configuration is still under the name base_model\n",
        "del fresh_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egD3M2h5EHwY"
      },
      "source": [
        "##Load tuned model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heYt2PBZjibj"
      },
      "source": [
        "Now, under `merged_path` we have the full tuned-model and we can load it as we did with the base one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497,
          "referenced_widgets": [
            "60051df3c7274eee8f39059650a35e30",
            "1a46c99e5c4746e48ace6fee0b5f2471",
            "93408ff795af4802b8f582765966301b",
            "fd0ff093e8e34c6c9aab011eb4d9c079",
            "03b02d87574547e5afa093054ef68be9",
            "1ce04a4bf52f4c38b3bcf50da2f58bca",
            "88eb9c2bcbd74824a4685648c02506ce",
            "945894c7c26f4fb188bc6242675c6ff3",
            "bc0ebd7973a846938a02861ea3863b8b",
            "7a972134d73140b6a4ed1345fec801df",
            "e88e51c7b8ba46709d2173a3a7736247",
            "7d0de51c5a6d45ccb7a8d4dba6ae3d0e",
            "fa9cbc7a11bb4c34bc6a9e34aa2af6b4",
            "827cda3d036c48d8bd5c118c4ff054e3",
            "fdd4be8f7daf4ad99cebcbcbe2e0a326",
            "1abfccfb7018448ca3909c7bc79e4bc8",
            "165977fda24644afa061a59c6757b8e8",
            "8ee7de5996c7439d880247597a3d7e8d",
            "87f9e6f5a87543c681ce595d5c357a1b",
            "31f775d2c6e54d509c10f63e2e79a0f5",
            "f922ee3198b2437584b05174d9fa3c35",
            "1145c9e6031f480ebb4cbd6728d49ae0",
            "a0630e3043a34ff2af7b363ef2714a5d",
            "dd54fe3b99994efa8954f678e0c55b68",
            "b1d3fdd30ba14ab38a3f2102a644c2da",
            "93cc3b66c040420f9723c7b6fed77455",
            "631b75d34cf64a708672edd4f563180f",
            "ba671b31f3294c5990e574ff217351fc",
            "ae70463b6ebc41b4a8621d8fd70b2bfd",
            "b27e49c364a6435a939fbab0874ac2c5",
            "0c2154fc97ed4b29ac619fcbf351da3a",
            "618fea92b9b441949916216995d02bee",
            "a7c4359467fe4a5cbef44c4b104c42e7",
            "9bf002633683489c953865b4567ab15b",
            "8d579258b5164e2187ed9e275b53290f",
            "37347cdac4bd476eb6f489ec8ffb5f6c",
            "38c93a43212b44d09353947dec96b58d",
            "39e45d4cb61646f98366439dda95f0aa",
            "c058b2abdbf44781ad7bdc72796ec402",
            "31e532fba90448beb5c1d15b5164702c",
            "161a3dcfa35748f0928c517c1f0f0554",
            "fe7d294ab94c453d92c3c9aa22c49bdf",
            "44b6e6b88d1a48cfb7cc2d41f6ce82d5",
            "caff6df424aa41b3a4caa8fe97caac3f",
            "9ea71a401ce74f7d87a9e9a862fb8414",
            "232c000bc4af48d483d509ac04bc7cc4",
            "1c459b3845de49b29d36cdbd3525dfe3",
            "69921456d89440c1883d221f38506d32",
            "8d760082cb5f484cab94f5f2a807bf33",
            "90f42cfca1534372a15741b2a1a2bb7d",
            "0c623ebfca554f9da8a24dfa0084cacf",
            "f278c1873b034af6b90d7cd0e0d0e818",
            "e9393aa2ab69475eab116cf1b7d28144",
            "b3dcbf8d8b0f40ccaaf99cad068e2c1a",
            "87ac35a73a2242f1bc2a4cc52910a122",
            "aab88994087a430fa1f9dbb64070ae59",
            "5549170292df4959bdfe245c17567243",
            "8b8ff0ee4b7d4db5a14c5b0c5d1d677e",
            "1101267ebec14623a1f2541b996fd019",
            "31cab3fc74134f769a82bc90e6783b56",
            "ae74345f48034344b68da285312fdc01",
            "b2288e152c6846138e1c424941e16726",
            "8d84a186cdcc45b7a48a359411b1a933",
            "84f33b1163ed4e94b6fe010b8ca780b0",
            "4240efdb45ff446fb3816026506b3c1c",
            "7d09a9b70f0346689104213c0365844c",
            "8e5f154e09b9450d81e3d9122e20fad2",
            "6f83113f4cc64252a854f9deb3fb64f7",
            "b0529039f5f445f8b462185aba1a68fb",
            "1555491918224d05b8409160f98722c7",
            "657516f86102497682f2e1fafb4dfc85",
            "f407666acedd4090a1ac2fd34fe19bc4",
            "032194943b7345228b3950beb7455854",
            "58a91dce2b2149f282607d626fc5e7ea",
            "b99ab77347bb4614959dc0d83ccf1e4b",
            "b11ab47d41684f5a853647e98113eadf",
            "ee34240ab55941898e24bcee8db33166",
            "0e3fb15300b54415aa1f857df4c8c4d0",
            "4d0f855c210a423aa777cab744fcc6a1",
            "948a135c3f744726b8ce0e35e8b70e97",
            "79ffa5e6572841308416c88157851b30",
            "afa1b21edb1c413498e277f80c211f5a",
            "b91d05297137407f902a7dac4b92f30c",
            "dc430be9cc69403b933d78e6cab22dfb",
            "e50fad6bd186424da5b9f2ceb5be5c6c",
            "6ee58be327034ebf984526921783a6d2",
            "17cf4c215a3d49bc93500593ef3d1aba",
            "2619682da4f74f899eff209c52daca41",
            "fdbd135f1264437aa3b9e8d8c2bf6c99",
            "72cdaa18412c4154af08a5578b610ebb",
            "eb5991298c914bda8903b2ff88392a2a",
            "80928657fc474c4da51c9241abefa38f",
            "4f49ba35327a4d138e3f9f0b36285966",
            "4ec8ca0f7a28478c9101c8cec3b5eed5",
            "fefd8ed8e0754fd4b16aeaa60ec2681a",
            "458e049c8c95473ebe3e1bc778a709a8",
            "90cee6e80b0a487bb2cbf4622dccb689",
            "55037079a7894a119cee36f7285db110",
            "f78f7552adb0425ab480d4b3e7af5f66",
            "a9439f6b05074c80b9a478e0b2e509e0",
            "a5ccfab3002f458c8a7bb1b8e2621ec5",
            "3fe3efe4a16d44da99dbbfc42e4e39c3",
            "b2f94fd9215f44e4b2159ec8a5c35ff3",
            "92948ff0206f4d358670c18b7595bf6d",
            "31784b2eb1fa466a8c3667f10e5573ce",
            "f7246959164b4f7684744498cfcc0ed3",
            "af8c4add3aa6462299adaba90081564a",
            "1210c64705e848e284dac92c908aed96",
            "d02c5ebb37ac4637bff732042d08b741",
            "7f614957d33e4f08b186614eb9041e79",
            "d4b11e0a87c5419f8e483f9752f7c9b7",
            "d077dd5441a648e9aaf2d343937f3e99",
            "0106ccd33c9d457294e25a962b16eb1d",
            "b7d9f1bdbdc74112858a9359505df890",
            "1b149cd4bd7c4fe086a30fde7e4c1591",
            "a0f8b2361a484af984d0d1c3c595b595",
            "9108dc55b4504a94ab460da8e4c3e086",
            "ff8d27cc68d7427993e287528ec7a4d7",
            "826bc26c639c45408513ad08ae442935",
            "30e19fb822194760a33fe8b9f218f521",
            "76ab5e31f70849e283ea3a9eaf339ff3",
            "5fbdd8d2109d4ecd9ff24100b842b146",
            "6d26a6e2d8134426a6873c67508dc632",
            "bd1f6a7c24274773a4479d64921918b8",
            "af0d120548bd4713a0c4adb92f5a8491",
            "97cb1397b12942e2ba085b011478c814",
            "b2d1b18ee44f4629806f4ded7a77a55a",
            "ac4316cc192e4b4aa0672d31f076367a",
            "a23ea09fd4c242a199115bedb73694c6",
            "75b3f538b0f44f63b02e91ce63da26fc",
            "5111da746466416ca86dc934ad9f36d9",
            "d2b0933c712d43e8a63d3ff81435be5a",
            "706b0521c1d64ccd8f79c09a5f1d584c",
            "d9d61de3dc524387a39d621690f53d67",
            "556dc00abb7b4355b23de3dbb208a9dd",
            "d145b158a743426bb0e0c41b72a2f2f0",
            "0095873e74234cd3ae7190df30ef9d57",
            "4b6c6598097b4ddc86caa7b8face49ef",
            "34a012e567c346a8bda6acb6b36014fd",
            "d3638851e9554d598fdb172538bc5a1a",
            "fddf3ec12a4e46faa18a420fd058f26d",
            "225714c42791417fb403b90908006471",
            "d95c6daa59de4933aaa9d12269803a3c",
            "0c4e1f6062dd48e8afde13c8d7829b06",
            "d7f6975708a047b484c595a0e8f7de95",
            "00af4b7d363b4707915dc69c1460f93e",
            "736a4892a21a4c568f7faaf572df8f7d",
            "6d26331d808543cda04b5e835a0e079a",
            "01a85c87f3474a17b0688722b8ecb0e7",
            "27a39f6c38ee40618b8e182452cc791b",
            "d8e182fbdd514e84911dea1594c26874",
            "8d2b749c117846ad9e76ad3f653233a3",
            "d9d3181e496842dc90933071352e2b4a",
            "3891e88c0759435da9e9b5101cad41c5",
            "ace5c86bd79c466c87f674d47eeb3f3c",
            "fae976609b8648cc8153577522f330b6",
            "65d16c72a3864f6d85939ae816781f17",
            "18bfcdcf6aa54844b7d23045b9362639",
            "342b6dfc82624d7fb6a66755a92d7846",
            "e47dd2ffbfdf4493864177970c33345c",
            "d7a0388d3e844266b4e09a98d2874583",
            "a0d1787b302d409f94dd11bd3f6def8c",
            "28d0413da88a41998de0175207be409a",
            "ec23ee2de1904702bcb1596911f1deed",
            "ef3fedfc2dc24c3da9669ceb2906697b"
          ]
        },
        "id": "MRRgBe4uAyjS",
        "outputId": "ae37d944-519a-4b16-adce-7aa0c1b070b5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60051df3c7274eee8f39059650a35e30",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/677 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d0de51c5a6d45ccb7a8d4dba6ae3d0e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0630e3043a34ff2af7b363ef2714a5d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9bf002633683489c953865b4567ab15b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00005-of-00006.safetensors:   0%|          | 0.00/4.86G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ea71a401ce74f7d87a9e9a862fb8414",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00006.safetensors:   0%|          | 0.00/4.86G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aab88994087a430fa1f9dbb64070ae59",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00003-of-00006.safetensors:   0%|          | 0.00/4.86G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e5f154e09b9450d81e3d9122e20fad2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00006-of-00006.safetensors:   0%|          | 0.00/2.68G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e3fb15300b54415aa1f857df4c8c4d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00004-of-00006.safetensors:   0%|          | 0.00/4.86G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fdbd135f1264437aa3b9e8d8c2bf6c99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00006.safetensors:   0%|          | 0.00/4.84G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9439f6b05074c80b9a478e0b2e509e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4b11e0a87c5419f8e483f9752f7c9b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/183 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5fbdd8d2109d4ecd9ff24100b842b146",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "706b0521c1d64ccd8f79c09a5f1d584c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c4e1f6062dd48e8afde13c8d7829b06",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ace5c86bd79c466c87f674d47eeb3f3c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/3.62M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tuned_model, tokenizer = load_model_and_tokenizer(\"NMantegazza/PubMedLLaMa\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjhGLQNAqeSS"
      },
      "source": [
        "##Evaluation of the two models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMu0kw2FS4ZR"
      },
      "source": [
        "We'll compare the standard LLaMA2-7B model and the fine-tuned version on the PubMedQA dataset using several evaluation metrics:\n",
        "  - Semantic metrics such as:\n",
        "\t  -\tROUGE\n",
        "\t  -\tBERTScore (precision, recall, and F1)\n",
        "  -\tClassification metrics\n",
        "\n",
        "These metrics will give us a well-rounded view of how both models perform.<br>\n",
        "For the ROUGE and BERTScore evaluation, we'll use the Hugging Face `evaluate` library.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4V57Nm8Vr2Xm"
      },
      "source": [
        "###Testing setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWkANAGPUBY6"
      },
      "outputs": [],
      "source": [
        "rouge = evaluate.load(\"rouge\")\n",
        "bertscore = evaluate.load(\"bertscore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pFwEUJ1mABg"
      },
      "source": [
        "To compute the classification report, we first need to extract the predicted labels from the generated text outputs, then filter out any invalid or unlabelled samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O53kPkZ7axRu"
      },
      "outputs": [],
      "source": [
        "def extract_label(text):\n",
        "    \"\"\"\n",
        "    Extracts 'yes' or 'no' from the start of a given answer string.\n",
        "    Converts to lowercase and strips whitespace.\n",
        "    Returns None if neither is found.\n",
        "    \"\"\"\n",
        "    text = text.strip().lower()\n",
        "    if text.startswith(\"yes\"):\n",
        "        return \"yes\"\n",
        "    elif text.startswith(\"no\"):\n",
        "        return \"no\"\n",
        "    return None\n",
        "\n",
        "def compute_class_report(preds, refs):\n",
        "    pred_labels = [extract_label(p) for p in preds]\n",
        "    ref_labels = [extract_label(r) for r in refs]\n",
        "\n",
        "    # Filter out any samples where label extraction failed\n",
        "    valid_indices = [i for i, (p, r) in enumerate(zip(pred_labels, ref_labels)) if p in {\"yes\", \"no\"} and r in {\"yes\", \"no\"}]\n",
        "    discarded_answers = len(preds) - len(valid_indices)\n",
        "    filtered_preds = [pred_labels[i] for i in valid_indices]\n",
        "    filtered_refs = [ref_labels[i] for i in valid_indices]\n",
        "\n",
        "    if not filtered_preds:\n",
        "        return {\"classification_accuracy\": None}\n",
        "\n",
        "    report_dict = classification_report(filtered_refs, filtered_preds, output_dict=True)\n",
        "\n",
        "    return {\n",
        "    \"classification_report\": report_dict,\n",
        "    \"number_of_answers_without_labels\": discarded_answers\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3MhfjM-UVtd"
      },
      "outputs": [],
      "source": [
        "def evaluate_all_metrics(predictions, references):\n",
        "    results = {}\n",
        "\n",
        "    # ROUGE\n",
        "    rouge_result = rouge.compute(predictions=predictions, references=references)\n",
        "    results.update(rouge_result)\n",
        "\n",
        "    # BERTScore\n",
        "    bert_result = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
        "    bert_means = {f\"bertscore_{k}\": np.mean(v) for k, v in bert_result.items() if k != \"hashcode\"}\n",
        "    results.update(bert_means)\n",
        "\n",
        "    #Classification report\n",
        "    accuracy = compute_class_report(predictions, references)\n",
        "    results.update(accuracy)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cqf_L5BFq7nc"
      },
      "source": [
        "Now that the evaluation function is set up, we can define our inference function.<br>\n",
        "This function generates model responses from our PuBMedQa datset. For each question, it creates the same prompt using for the fine-tuning step. It uses a text-generation `pipeline` to produce the answers, collects the predictions, reference answers, and questions, and returns them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sl2ijEMy-vJt"
      },
      "outputs": [],
      "source": [
        "def new_formatting_prompts_func(new_example, examples=[]):\n",
        "    instruction = (\n",
        "        \"### Instruction:\\n\"\n",
        "        \"You are a medical expert. Based on the following context, answer the question with 'Yes' or 'No', followed by a clear and accurate explanation.\\n\"\n",
        "    )\n",
        "    body = \"\"\n",
        "\n",
        "    for i, ex in enumerate(examples, 1):\n",
        "        body += (\n",
        "            f\"\\n### Example {i}:\\n\"\n",
        "            f\"### Context:\\n{ex['context']}\\n\"\n",
        "            f\"### Question:\\n{ex['question']}\\n\"\n",
        "            f\"### Answer:\\n{ex['answer']}\\n\\n\"\n",
        "        )\n",
        "\n",
        "    # Append the test instance\n",
        "    body += (\n",
        "        f\"\\n###End of examples\\n\"\n",
        "        f\"### Now answer the following:\\n\"\n",
        "        f\"### Context:\\n{new_example['context']}\\n\"\n",
        "        f\"### Question:\\n{new_example['question']}\\n\"\n",
        "        f\"### Answer:\\n\"\n",
        "    )\n",
        "    #print(\"Prompt: \", instruction+body)\n",
        "\n",
        "    return instruction + body"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mK3fQDuCUi6Z"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "def generate_responses(dataset, model, tokenizer, examples=[]):\n",
        "    preds = []\n",
        "    refs = []\n",
        "    questions_out = []\n",
        "\n",
        "    questions = dataset[\"question\"].tolist()\n",
        "    contexts = dataset[\"context\"].tolist() if use_context else [\"\"] * len(dataset)\n",
        "    references = dataset[\"answer\"].apply(str.strip).tolist()\n",
        "\n",
        "    generation_pipeline = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "\n",
        "    for i, (q, c, ref) in enumerate(zip(questions, contexts, references), 1):\n",
        "        print(f\"Processing example {i}/{len(questions)}...\")\n",
        "\n",
        "        if len(examples) != 0:\n",
        "            prompt = new_formatting_prompts_func({\"context\": c, \"question\": q}, examples)\n",
        "        else:\n",
        "            prompt = (\n",
        "                \"### Instruction:\\n\"\n",
        "                f\"You are a medical expert. Based on the following context, answer the question with 'Yes' or 'No', followed by a clear and accurate explanation.\\n\"\n",
        "                f\"### Context:{c}\\n\"\n",
        "                f\"### Question:{q}\\n\"\n",
        "                \"### Answer:\"\n",
        "            )\n",
        "\n",
        "        max_new_tokens = 128\n",
        "\n",
        "        response = generation_pipeline(\n",
        "            prompt,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=False,\n",
        "            repetition_penalty=1.1,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )[0]['generated_text']\n",
        "\n",
        "        answer = response[len(prompt):].strip()\n",
        "        preds.append(answer)\n",
        "        refs.append(ref)\n",
        "        questions_out.append(q)\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        clear_output(wait=True)  # Clear stdout after each iteration\n",
        "\n",
        "    return questions_out, preds, refs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNBweKiG26_d"
      },
      "outputs": [],
      "source": [
        "#Pretty print the evaluation results\n",
        "def print_metrics(metrics: dict, title: str = \"Evaluation Metrics\"):\n",
        "    def print_line(char='-', width=60):\n",
        "        print(char * width)\n",
        "\n",
        "    print(f\"\\n=== {title} ===\")\n",
        "    print(f\"{'Metric':<40} {'Value':>15}\")\n",
        "    print_line()\n",
        "\n",
        "    for k, v in metrics.items():\n",
        "        if isinstance(v, dict) and k == \"classification_report\":\n",
        "            print(f\"{k}:\")\n",
        "            print_classification_report(v)\n",
        "        elif isinstance(v, (float, int)):\n",
        "            print(f\"{k:<40} {v:>15.4f}\")\n",
        "        else:\n",
        "            print(f\"{k:<40} {str(v):>15}\")\n",
        "    print_line()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "def print_classification_report(report: dict):\n",
        "    labels = [label for label in report if label not in (\"accuracy\", \"macro avg\", \"weighted avg\")]\n",
        "    specials = [k for k in (\"accuracy\", \"macro avg\", \"weighted avg\") if k in report]\n",
        "\n",
        "    header = f\"{'Label':<10} {'Precision':>10} {'Recall':>10} {'F1-Score':>10} {'Support':>10}\"\n",
        "    print(header)\n",
        "    print(\"-\" * len(header))\n",
        "\n",
        "    def print_row(label, scores):\n",
        "        precision = scores.get(\"precision\", 0.0)\n",
        "        recall = scores.get(\"recall\", 0.0)\n",
        "        f1 = scores.get(\"f1-score\", 0.0)\n",
        "        support = scores.get(\"support\", 0.0)\n",
        "        print(f\"{label:<10} {precision:>10.4f} {recall:>10.4f} {f1:>10.4f} {support:>10.0f}\")\n",
        "\n",
        "    for label in labels + specials:\n",
        "        if label == \"accuracy\":\n",
        "            print(f\"\\n{'Accuracy':<10} {report[label]:>10.4f}\")\n",
        "        else:\n",
        "            print_row(label, report[label])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oojfnDVSw9P"
      },
      "source": [
        "### Test the two models on PubMedQA evaluation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Lp0LTFRkxdWj",
        "outputId": "c2d78c46-4791-4cae-9ed3-3c896c986a62"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LlamaForCausalLM(\n",
              "  (model): LlamaModel(\n",
              "    (embed_tokens): Embedding(32000, 4096)\n",
              "    (layers): ModuleList(\n",
              "      (0-31): 32 x LlamaDecoderLayer(\n",
              "        (self_attn): LlamaAttention(\n",
              "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "          (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "          (v_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): LlamaMLP(\n",
              "          (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "      )\n",
              "    )\n",
              "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#let's put the two model in eval mode for better results\n",
        "base_model.eval()\n",
        "tuned_model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcWlen4_8_XX"
      },
      "source": [
        "Due to time constraints, we'll downsample the evaluation dataset to 100 samples, which should still give us a good insight into the performance of both models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oUnr1cn_Hmv"
      },
      "outputs": [],
      "source": [
        "#down sample the eval set again\n",
        "eval_dataset_2 = eval_dataset.sample(n=100, random_state=42).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KcDoE9WjrXsP"
      },
      "outputs": [],
      "source": [
        "b_quests, b_preds, b_refs = generate_responses(eval_dataset_2, base_model, base_tokenizer)\n",
        "base_metrics = evaluate_all_metrics(b_preds, b_refs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoHpuzc2--3S",
        "outputId": "06de0193-2adb-4785-8548-29d114fe3230"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Base Model Evaluation Metrics ===\n",
            "Metric                                             Value\n",
            "------------------------------------------------------------\n",
            "rouge1                                            0.0984\n",
            "rouge2                                            0.0386\n",
            "rougeL                                            0.0756\n",
            "rougeLsum                                         0.0770\n",
            "bertscore_precision                               0.7689\n",
            "bertscore_recall                                  0.8440\n",
            "bertscore_f1                                      0.8039\n",
            "classification_report:\n",
            "Label       Precision     Recall   F1-Score    Support\n",
            "------------------------------------------------------\n",
            "no             0.0000     0.0000     0.0000         29\n",
            "yes            0.5735     1.0000     0.7290         39\n",
            "\n",
            "Accuracy       0.5735\n",
            "macro avg      0.2868     0.5000     0.3645         68\n",
            "weighted avg     0.3289     0.5735     0.4181         68\n",
            "number_of_answers_without_labels                 32.0000\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "#print results\n",
        "print_metrics(base_metrics, \"Base Model Evaluation Metrics\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RTKM71yATJj"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "The base model seems to understand the meaning of the text fairly well (good BERTScore), but it doesn't match the exact words of the reference very closely (low ROUGE scores).\n",
        "\n",
        "For classification, the model predicts \"yes\" almost all the time. It gets all the \"yes\" answers right, but misses every \"no\" — which brings the overall accuracy to about 57%.\n",
        "\n",
        "Also, 32 answers were skipped because they didn't have labels. An indication that the model struggled to follow the prompt correctly.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBsdquHY9w5v"
      },
      "source": [
        "In order to have more intesrseting results we may use a one-shot/few-shot learning technique, we modify the prompt to show the model an example of answer/question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302,
          "referenced_widgets": [
            "21c46dc79f0c421da723b82fc8fec860",
            "319f4daf6f75432bb5262b1e409073e2",
            "9f5460032c8c4819ba49c803bd8a0844",
            "4478bed8ef5a408cb008d75de65d88c2",
            "f7ff64abc83746c984a595f3b7a0d384",
            "51418ab0d1a041bbbe3fe681a82944e9",
            "4547c4f47bd74423bc2b7fe3bdf8fffd",
            "3a6982fbac8e480cbae5b7d4107f8ad3",
            "f0788c1b20f542a29a428e58dc0b301d",
            "68925eb6e0cf45eda33402baea81d6fc",
            "55f7e465d6d34feb9d202f3ee04801ec",
            "974a745e38a74fcdbfa6c51d7d57aeb9",
            "d756a7e2c57843f599e4d41d5413a8ba",
            "4a80725a1fe34b00ae3e9200d3a3dcca",
            "bb1a1d1b3c504ec7a8c4157d580b3cff",
            "e48d30ed2dfb42aa9361691be08f618c",
            "7cd7a486b260479d8b0d2cc87a7d1183",
            "7516fd052a014e22850dc31493bb0fb0",
            "f63a607162584c2ea61c93dcb9d88a90",
            "ce7ccd4efb8e45aab1e96f8d9ac9fdae",
            "c95f54a4d33c435db52765dd0cd9df12",
            "88e2ac10ce2240c48693eb1ae26b73af",
            "888b492aed22412a8eef6f9fdba584a5",
            "37a6b1137ca844e79a5084b9610e9604",
            "5efb035924fb4f879bce4f4bd38fb7f4",
            "2ec78c33442245beaaa299fd12d36f61",
            "d356e10f041c4950be9b21f52f9844f5",
            "0b12237934e54ca0a5e4cb412b23c35f",
            "81ea736c204c46f18c52d371ee5cbe77",
            "fcbb0b2dbf4c4be0a5653f73d740f58d",
            "09aa7b35b1bb4e3cbc1478ba91bb41bd",
            "d53eeeaf3a084fb88410f7793d25326a",
            "1c235321d0c9483689a7951535e8181b",
            "c93533d6a1244a37bca8024729b9b6eb",
            "031bd735c3aa4090841a7571e8273e62",
            "e22d8b1f44ca49f7893af42bdccd6efa",
            "a9f35456e9994e7da8b8275522cd80fa",
            "300fa48d2ebf40f28c7125fda7d9c37c",
            "4b45ef611aa844e69c6ff5fb66df9aa4",
            "c38a8f480b164733ad787cc5d3d8ed3e",
            "aef1969411434ddba776249682394e2c",
            "0f4c6b4aac304f59b93614bbcf0ea6c3",
            "c3bf60a92d724c578c2fec48d7b5a38a",
            "48a4330d912345b09e01627c3ee8cbe1",
            "b95d9bc003b04146b9e57995c04b40df",
            "ba3f1f86d54040699068160773f1fd70",
            "e9f1fdc04af246abbd3f90b02791f8bc",
            "f0c605b0429f48558c2e0109ad227364",
            "2ecaaa7a7c924bb788720a2df802731a",
            "71529180149c4c2bbf68d398e3398567",
            "0d3a4572c53748e0993702f3234e6fe2",
            "829876c40ce0400f98a77db30fb4f68b",
            "79712a317c9b4d68a1a0ae490854015e",
            "d73f8717afc04b3d98587696182e2ece",
            "8d3c11d22ae548ba854968ea382d3854",
            "ca2842f4f7d54c9ca21eafb3086ced79",
            "5b5e230b0792412fab37d6969a543243",
            "6c9dc2e8d1f14888845cbaa962bd4aa7",
            "f4998af30f9040b5b293052540663602",
            "d64e671d34fd4ec6b06ba5b8024f7a49",
            "6ccd4486854446118ce42440c0f3d7c7",
            "fbff5e962e14498cb35b0a3bc9f6eb28",
            "dd6de52ebbb74a77b86d29b7eaab2920",
            "b4c4bcce10b44743864d93bbb8e77383",
            "634c6ebd0925428099b86c040f6acc54",
            "1d2408c91dfa44aa8e7250e7aac4f67f"
          ]
        },
        "id": "Q3M7afnw_Lgs",
        "outputId": "bddabd25-05d2-420e-b48e-bbfde093776f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21c46dc79f0c421da723b82fc8fec860",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "974a745e38a74fcdbfa6c51d7d57aeb9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "888b492aed22412a8eef6f9fdba584a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c93533d6a1244a37bca8024729b9b6eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b95d9bc003b04146b9e57995c04b40df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca2842f4f7d54c9ca21eafb3086ced79",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "#start with one-shot\n",
        "\n",
        "#sample one from the train_set\n",
        "example_list = train_dataset.sample(n=1, random_state=42).to_dict(orient='records')\n",
        "\n",
        "one_shot_quests, one_shot_preds, one_shot_refs = generate_responses(eval_dataset_2, base_model, base_tokenizer,example_list)\n",
        "one_shot_metrics = evaluate_all_metrics(one_shot_preds, one_shot_refs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igMjAQiFCcj_",
        "outputId": "5f304759-7c53-41b5-8ad8-88bb32dd8fb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== One shot Model Evaluation Metrics ===\n",
            "Metric                                             Value\n",
            "------------------------------------------------------------\n",
            "rouge1                                            0.3290\n",
            "rouge2                                            0.1364\n",
            "rougeL                                            0.2625\n",
            "rougeLsum                                         0.2636\n",
            "bertscore_precision                               0.9073\n",
            "bertscore_recall                                  0.8867\n",
            "bertscore_f1                                      0.8966\n",
            "classification_report:\n",
            "Label       Precision     Recall   F1-Score    Support\n",
            "------------------------------------------------------\n",
            "no             1.0000     0.3137     0.4776         51\n",
            "yes            0.5833     1.0000     0.7368         49\n",
            "\n",
            "Accuracy       0.6500\n",
            "macro avg      0.7917     0.6569     0.6072        100\n",
            "weighted avg     0.7958     0.6500     0.6046        100\n",
            "number_of_answers_without_labels                  0.0000\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "print_metrics(one_shot_metrics, \"One shot Model Evaluation Metrics\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apq2QtLYA9Oa"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgXGoO7DCqQB",
        "outputId": "9520c884-cfec-49f0-f5fd-d93e31451497"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing example 100/100...\n"
          ]
        }
      ],
      "source": [
        "#few shot\n",
        "examples = train_dataset.sample(n=5, random_state=42).to_dict(orient='records')\n",
        "\n",
        "few_shot_quests, few_shot_preds, few_shot_refs = generate_responses(eval_dataset_2, base_model, base_tokenizer, examples)\n",
        "few_shot_metrics = evaluate_all_metrics(few_shot_preds, few_shot_refs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yTI0HBaElc8",
        "outputId": "60675d26-f3a3-487c-bdd6-6b428a359f41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Few shot Model Evaluation Metrics ===\n",
            "Metric                                             Value\n",
            "------------------------------------------------------------\n",
            "rouge1                                            0.3719\n",
            "rouge2                                            0.1591\n",
            "rougeL                                            0.3040\n",
            "rougeLsum                                         0.3063\n",
            "bertscore_precision                               0.9021\n",
            "bertscore_recall                                  0.8892\n",
            "bertscore_f1                                      0.8954\n",
            "classification_report:\n",
            "Label       Precision     Recall   F1-Score    Support\n",
            "------------------------------------------------------\n",
            "no             0.9149     0.8431     0.8776         51\n",
            "yes            0.8491     0.9184     0.8824         49\n",
            "\n",
            "Accuracy       0.8800\n",
            "macro avg      0.8820     0.8808     0.8800        100\n",
            "weighted avg     0.8826     0.8800     0.8799        100\n",
            "number_of_answers_without_labels                  0.0000\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "print_metrics(few_shot_metrics, \"Few shot Model Evaluation Metrics\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgEqzTQysYbz"
      },
      "outputs": [],
      "source": [
        "#test the tuned model\n",
        "t_quests, t_preds, t_refs = generate_responses(eval_dataset_2, tuned_model, tokenizer)\n",
        "tuned_metrics = evaluate_all_metrics(t_preds, t_refs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kb0c6tV_e3J",
        "outputId": "5711ed4a-e1ba-450e-9244-7867f423ae75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Tuned Model Evaluation Metrics ===\n",
            "Metric                                             Value\n",
            "------------------------------------------------------------\n",
            "rouge1                                            0.4060\n",
            "rouge2                                            0.1917\n",
            "rougeL                                            0.3269\n",
            "rougeLsum                                         0.3275\n",
            "bertscore_precision                               0.9165\n",
            "bertscore_recall                                  0.8970\n",
            "bertscore_f1                                      0.9064\n",
            "classification_report:\n",
            "Label       Precision     Recall   F1-Score    Support\n",
            "------------------------------------------------------\n",
            "no             0.7656     0.9608     0.8522         51\n",
            "yes            0.9444     0.6939     0.8000         49\n",
            "\n",
            "Accuracy       0.8300\n",
            "macro avg      0.8550     0.8273     0.8261        100\n",
            "weighted avg     0.8532     0.8300     0.8266        100\n",
            "number_of_answers_without_labels                  0.0000\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "#Print results\n",
        "print_metrics(tuned_metrics, \"Tuned Model Evaluation Metrics\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv65PeLd__Qi"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "The tuned model shows a big improvement. ROUGE scores are much higher, meaning its outputs are more similar to the reference texts. BERTScore is also very strong, showing it captures the meaning well.\n",
        "\n",
        "For classification, the model performs well on both \"yes\" and \"no\" labels. It predicts \"no\" very accurately (96% recall), and still does well on \"yes\" (94% precision). Overall accuracy is 83%, with a balanced performance across both classes.\n",
        "\n",
        "Also, no predictions were skipped this time — all responses had proper labels. The fine-tuning clearly helped the model become more reliable and balanced.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4101mmU1BCW"
      },
      "source": [
        "###Human testing on some PubMedQA questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-eWjaemoVmK"
      },
      "source": [
        "To further compare the two models, we can perform human evaluation on their answers for a small set of samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRCwzm0K6Gpn",
        "outputId": "7a3bc463-4f0a-4efb-e89d-1bbb1682f289"
      },
      "outputs": [],
      "source": [
        "example_list = train_dataset.sample(n=1, random_state=42).to_dict(orient='records')\n",
        "examples = train_dataset.sample(n=5, random_state=42).to_dict(orient='records')\n",
        "\n",
        "\n",
        "# Sample a small subset for evaluation\n",
        "sample_set = eval_dataset.sample(n=5, random_state=42).reset_index(drop=True)\n",
        "# fine-tuned predictions\n",
        "ft_quests, ft_preds, ft_refs = generate_responses(sample_set, tuned_model, tokenizer)\n",
        "#one_shot predictions\n",
        "one_shot_quests, one_shot_preds, one_shot_refs = generate_responses(sample_set, base_model,base_tokenizer,example_list)\n",
        "#few_shot predictions\n",
        "few_shot_quests, few_shot_preds, few_shot_refs = generate_responses(sample_set, base_model,base_tokenizer,examples)\n",
        "# base model predictions\n",
        "base_quests, base_preds, base_refs = generate_responses(sample_set, base_model,base_tokenizer)\n",
        "# Build a DataFrame to compare results\n",
        "compare_df = pd.DataFrame({\n",
        "    \"Question\": base_quests,\n",
        "    \"Fine-tuned Prediction\": ft_preds,\n",
        "    \"One-shot Prediction\": one_shot_preds,\n",
        "    \"Few-shot Prediction\": few_shot_preds,\n",
        "    \"Base Model Prediction\": base_preds,\n",
        "    \"Reference\": base_refs\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1259
        },
        "id": "h302DIIe_7bo",
        "outputId": "47fd9816-a1fa-49d9-db76-f635a6b2750f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"compare_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Is genetic heterogeneity of surgically resected prostate carcinomas and their biopsy specimens related to their histologic differentiation?\",\n          \"Does [ Pre-operative smoking cessation always reduce the incidence of surgical site infection after gastrointestinal surgery ]?\",\n          \"Is chromogranin A a potential prognostic marker in prostate cancer patients treated with enzalutamide?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fine-tuned Prediction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"no, Genetic heterogeneity is not related to histologic differentiation of prostatic carcinoma.\",\n          \"no, Pre-operative smoking cessation does not always reduce the incidence of SSI after gastrointestinal surgery.\",\n          \"yes, Our results suggest that CgA is an independent prognosticator for OS in metastatic CRPC patients treated with enzalutamide.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"One-shot Prediction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"yes, Genetic heterogeneity of surgically resected prostate carcinomas and their biopsy specimens is related to their histologic differentiation.\",\n          \"yes, Pre-operative smoking cessation does not reduce the incidence of SSI after gastrointestinal surgery.\",\n          \"yes, Chromogranin A is a potential prognostic marker in prostate cancer patients treated with enzalutamide.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Few-shot Prediction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"no, The results suggest that genetic heterogeneity may be associated with the histologic differentiation of prostatic carcinoma.\",\n          \"no, Pre-operative smoking cessation does not always reduce the incidence of SSI after gastrointestinal surgery.\",\n          \"yes, Chromogranin A may be considered as a potential prognostic marker in prostate cancer patients treated with enzalutamide.\\n\\n\\n### End of examples\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Base Model Prediction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Yes. Genetic heterogeneity is related to histological differentiation.\\n### Explanation:\\nThe authors found that the overall LOH rate was significantly lower in foci at classification pT2 (1 of 28 foci, 3%) compared with those at classification pT3 (13 of 44 foci, 30%). In pT3 samples, LOH events in extraglandular foci (9 of 23 foci, 39%) tended to be more frequent compared with those in intraglandular foci (8 of 4\",\n          \"### Explanation:\",\n          \"Yes. Chromogranin A is a potential prognostic marker in prostate cancer patients treated with enzalutamide.\\n### Explanation:\\nChromogranin A (CgA) is a protein that is secreted from neuroendocrine cells and is involved in the regulation of blood pressure and the release of hormones such as adrenalin and noradrenalin. It has been reported to be overexpressed in several types of cancers including prostate cancer. The aim of our study was to evaluate whether CgA could be used as\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Reference\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"yes, Prostate carcinoma is a genetically multicentric carcinoma, and the genetic heterogeneity is well correlated with histologic differentiation. The frequency of LOH events increased according to the degree of tumor progression.\",\n          \"no, Pre-operative smoking cessation does not reduce the incidence of SSI. However, since continuation of smoking has no benefits for the safety of surgery, anesthesiologists must advice patients to quit smoking before surgery.\",\n          \"yes, In CRPC patients treated with enzalutamide, the evaluation of serum CgA levels could be an useful prognostic factor because of the strong association between CgA value more than three times the UNV and clinical outcome, independently from PSA response.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "compare_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-83db3745-2de9-43f7-8bad-000aafd6afc7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Fine-tuned Prediction</th>\n",
              "      <th>One-shot Prediction</th>\n",
              "      <th>Few-shot Prediction</th>\n",
              "      <th>Base Model Prediction</th>\n",
              "      <th>Reference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Does perineural invasion on prostate needle bi...</td>\n",
              "      <td>no, Perineural invasion does not appear to be ...</td>\n",
              "      <td>no, Perineural invasion does not appear to be ...</td>\n",
              "      <td>no, The presence of PNI on prostate needle bio...</td>\n",
              "      <td>Yes. Perineural invasion is an independent pre...</td>\n",
              "      <td>no, Perineural invasion is not a significant p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Is genetic heterogeneity of surgically resecte...</td>\n",
              "      <td>no, Genetic heterogeneity is not related to hi...</td>\n",
              "      <td>yes, Genetic heterogeneity of surgically resec...</td>\n",
              "      <td>no, The results suggest that genetic heterogen...</td>\n",
              "      <td>Yes. Genetic heterogeneity is related to histo...</td>\n",
              "      <td>yes, Prostate carcinoma is a genetically multi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Is chromogranin A a potential prognostic marke...</td>\n",
              "      <td>yes, Our results suggest that CgA is an indepe...</td>\n",
              "      <td>yes, Chromogranin A is a potential prognostic ...</td>\n",
              "      <td>yes, Chromogranin A may be considered as a pot...</td>\n",
              "      <td>Yes. Chromogranin A is a potential prognostic ...</td>\n",
              "      <td>yes, In CRPC patients treated with enzalutamid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Is [ Percentage of local recurrence following ...</td>\n",
              "      <td>no, The percentage of local recurrences follow...</td>\n",
              "      <td>yes, The percentage of local recurrences follo...</td>\n",
              "      <td>no, The percentage of local recurrences follow...</td>\n",
              "      <td>Yes\\n### Explanation:\\nThe performance indicat...</td>\n",
              "      <td>no, The percentage of local recurrences follow...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Does [ Pre-operative smoking cessation always ...</td>\n",
              "      <td>no, Pre-operative smoking cessation does not a...</td>\n",
              "      <td>yes, Pre-operative smoking cessation does not ...</td>\n",
              "      <td>no, Pre-operative smoking cessation does not a...</td>\n",
              "      <td>### Explanation:</td>\n",
              "      <td>no, Pre-operative smoking cessation does not r...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83db3745-2de9-43f7-8bad-000aafd6afc7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-83db3745-2de9-43f7-8bad-000aafd6afc7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-83db3745-2de9-43f7-8bad-000aafd6afc7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c41fcdbc-e38e-4b4d-bcdb-6dc5820509c0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c41fcdbc-e38e-4b4d-bcdb-6dc5820509c0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c41fcdbc-e38e-4b4d-bcdb-6dc5820509c0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_40cd6bae-e407-4a99-9ad6-57eb7b5f1865\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('compare_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_40cd6bae-e407-4a99-9ad6-57eb7b5f1865 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('compare_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                            Question  \\\n",
              "0  Does perineural invasion on prostate needle bi...   \n",
              "1  Is genetic heterogeneity of surgically resecte...   \n",
              "2  Is chromogranin A a potential prognostic marke...   \n",
              "3  Is [ Percentage of local recurrence following ...   \n",
              "4  Does [ Pre-operative smoking cessation always ...   \n",
              "\n",
              "                               Fine-tuned Prediction  \\\n",
              "0  no, Perineural invasion does not appear to be ...   \n",
              "1  no, Genetic heterogeneity is not related to hi...   \n",
              "2  yes, Our results suggest that CgA is an indepe...   \n",
              "3  no, The percentage of local recurrences follow...   \n",
              "4  no, Pre-operative smoking cessation does not a...   \n",
              "\n",
              "                                 One-shot Prediction  \\\n",
              "0  no, Perineural invasion does not appear to be ...   \n",
              "1  yes, Genetic heterogeneity of surgically resec...   \n",
              "2  yes, Chromogranin A is a potential prognostic ...   \n",
              "3  yes, The percentage of local recurrences follo...   \n",
              "4  yes, Pre-operative smoking cessation does not ...   \n",
              "\n",
              "                                 Few-shot Prediction  \\\n",
              "0  no, The presence of PNI on prostate needle bio...   \n",
              "1  no, The results suggest that genetic heterogen...   \n",
              "2  yes, Chromogranin A may be considered as a pot...   \n",
              "3  no, The percentage of local recurrences follow...   \n",
              "4  no, Pre-operative smoking cessation does not a...   \n",
              "\n",
              "                               Base Model Prediction  \\\n",
              "0  Yes. Perineural invasion is an independent pre...   \n",
              "1  Yes. Genetic heterogeneity is related to histo...   \n",
              "2  Yes. Chromogranin A is a potential prognostic ...   \n",
              "3  Yes\\n### Explanation:\\nThe performance indicat...   \n",
              "4                                   ### Explanation:   \n",
              "\n",
              "                                           Reference  \n",
              "0  no, Perineural invasion is not a significant p...  \n",
              "1  yes, Prostate carcinoma is a genetically multi...  \n",
              "2  yes, In CRPC patients treated with enzalutamid...  \n",
              "3  no, The percentage of local recurrences follow...  \n",
              "4  no, Pre-operative smoking cessation does not r...  "
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compare_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "988RSRTaA1VT"
      },
      "source": [
        "\n",
        "The fine-tuned model's answers are clearly better compared to the reference answers. While the base model often falls into infinite text loops and struggles to properly format its responses, frequently falling to follow the prompt's ### structure."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "cU4-GOxqP7TT",
        "XzAeXKPmApuR",
        "egD3M2h5EHwY"
      ],
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
